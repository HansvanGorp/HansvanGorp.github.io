---
title: "A generative foundation model for five-class sleep staging with arbitrary sensor input"
collection: publications
permalink: /publication/2024-08-09
date: 2024-08-09
venue: 'arXiv preprint'
paperurl: 
citation: 
---

Hans van Gorp, Merel M van Gilst, Pedro Fonseca, Fokke B van Meulen, Johannes P van Dijk, Sebastiaan Overeem, and Ruud J G van Sloun, "A generative foundation model for five-class sleep staging with arbitrary sensor input," arXiv preprint, August 2024.
\[[link](https://arxiv.org/abs/2408.15253)\]
\[[pdf](http://hansvangorp.github.io/files/2024-08-09.pdf)\]

Gold-standard sleep scoring as performed by human technicians is based on a subset of polysomnographic sensor signals, namely the EEG, EOG, and EMG. Polysomnography, however, consists of many more signal derivations that could potentially be used to perform sleep staging, including cardiac and respiratory modalities. Leveraging this variety in signals would offer advantages, for example by increasing reliability, resilience to signal loss, and application to long-term non-obtrusive recordings. This paper proposes a deep generative foundation model for fully automatic sleep staging from a plurality of sensors and any combination thereof. We trained a score-based diffusion model with a transformer backbone using a dataset of 1947 expert-labeled overnight sleep recordings with 36 different signals, including neurological, cardiac, respiratory flow, and respiratory effort signals. We achieve zero-shot inference on any sensor set by using a novel Bayesian factorization of the score function across the sensors, i.e., it does not require retraining on specific combinations of signals. On single-channel EEG, our method reaches the performance limit in terms of polysomnography inter-rater agreement (5-class accuracy 85.6%, Cohen’s kappa 0.791). At the same time, the method offers full flexibility to use any sensor set derived from other modalities, for example, as typically used in polygraphic home recordings that include finger PPG, nasal cannula and thoracic belt (5-class accuracy 79.0%, Cohen’s kappa of 0.697), or by combining derivations not typically used for sleep staging such as the tibialis and sternocleidomastoid EMG (5-class accuracy 71.0%, Cohen’s kappa of 0.575). Additionally, we propose a novel interpretability metric in terms of information gain per sensor and show that this is linearly correlated with classification performance. Lastly, our foundation model allows for post-hoc addition of entirely new sensor modalities by merely training a score estimator on the novel input.